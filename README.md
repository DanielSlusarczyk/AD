## :small_blue_diamond: Repository
 <div align="justify">
  This repository contatins an example approach to implementing an automatic differentiation library intended for training a Recurrent Neural Network (RNN). The implementation was prepared based on the use of the backpropagation algorithm and the Julia programming language to create a classifier of handwritten numbers of the MNIST dataset.
 </div>

## :small_blue_diamond: Automatic Differentiation (AD)
 <div align="justify">
   Derivatives of functions form the foundation of mathematical analysis, playing a crucial role in both theory and practical applications. In forms such as gradients and Hessian matrices, derivatives are an indispensable component of machine learning (ML) — a field that is rapidly evolving in the context of the dynamic progress of artificial intelligence (AI). The need for efficient and accurate computation of derivatives has led to the development of a technique known as automatic differentiation (AD), which is the subject of this repository.

   Existing approaches to differentiation have certain limitations that significantly hinder their application, for instance, in the training of neural networks. ”Autodiff” is the method that is gaining significance in the discussed field of science. It enables the numerical computation of the derivative of a function defined by a computer program with minimal effort from the user. The core of AD’s operation is the chain rule and the ability to represent mathematical formulas as a finite sequence of n-argument operations.
</div>


## :small_blue_diamond: Julia (programming language)
![Julia logo](https://github.com/JuliaLang/julia-logo-graphics/blob/master/images/julia-language-logo-white-border.svg)

 <div align="justify">
The effectiveness of training neural networks depend not only on the chosen differentiation method but also on the selected programming language. In this regard, a candidate worth considering is Julia, which is becoming an increasingly popular choice in the context of numerical computations.

Julia is a new programming language developed by Jeff Bezanson, Alan Edelman, Stefan Karpinski, and Viral B. Shah (MIT) in 2012. Julia represents a successful attempt to extract the most important advantages of other programming languages. A distinctive feature of Julia is its ability to allow users to balance high performance with conveniences such as dynamic typing and writing high-level code. This enables programmers to write clear, generic, and abstract implementations while simultaneously generating fast machine code. These factors present a strong argument for choosing Julia to create an AD library.
 </div>
